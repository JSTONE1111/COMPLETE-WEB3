# ðŸ—ï¸ Merging 500 Repositories: Complete Guide

## ðŸŽ¯ Overview

This system handles **mass repository consolidation** with:
- âœ… Automatic repository categorization
- âœ… Batch processing (prevents memory issues)
- âœ… Parallel execution (configurable)
- âœ… Comprehensive logging
- âœ… Error recovery
- âœ… Progress tracking

---

## ðŸ“‹ Prerequisites

### Install Dependencies
```bash
# Python (for repo list generator)
python3 --version  # Requires 3.7+
pip3 install requests

# Git
git --version  # Requires 2.9+

# Optional: GitHub CLI (recommended)
gh --version
```

### GitHub Access Token
Create a token at: https://github.com/settings/tokens

**Required scopes**:
- `repo` (Full control of private repositories)
- `read:org` (Read org data)

```bash
export GITHUB_TOKEN="ghp_your_token_here"
```

---

## ðŸš€ Step-by-Step Process

### Step 1: Generate Repository List

```bash
# For an organization
python3 generate-repo-list.py your-org-name

# For a user account
python3 generate-repo-list.py username --user

# With authentication (higher rate limits)
python3 generate-repo-list.py your-org --token $GITHUB_TOKEN
```

**Output**: `repos-list.txt` with format:
```
# === FRONTEND (25 repos) ===
https://github.com/org/dashboard.git:frontend/dashboard
https://github.com/org/web-app.git:frontend/web-app

# === BACKEND (150 repos) ===
https://github.com/org/api-users.git:backend/api-users
https://github.com/org/service-payments.git:backend/service-payments
```

### Step 2: Review & Customize

Edit `repos-list.txt`:
```bash
nano repos-list.txt
```

**Tips**:
- Comment out repos you don't want: `# https://...`
- Change target directories as needed
- Group related services together
- Skip archived/deprecated repos

### Step 3: Run the Merger

```bash
# Make script executable
chmod +x merge-repos.sh

# Run with default settings (10 parallel jobs)
./merge-repos.sh repos-list.txt

# Or customize for your system
PARALLEL_JOBS=20 ./merge-repos.sh repos-list.txt
```

**What happens**:
1. Creates `monorepo/` directory
2. Processes repos in batches of 50
3. Merges each into subdirectories
4. Logs everything to `merge-logs/`
5. Shows real-time progress

### Step 4: Review Results

```bash
# Check summary
cat merge-logs/summary.txt

# Review failed repos (if any)
grep -r "Error:" merge-logs/

# Inspect final structure
tree -L 2 monorepo/
```

### Step 5: Push to GitHub

```bash
cd monorepo

# Create new repo on GitHub first
gh repo create your-org/monorepo --public

# Or use web UI: https://github.com/new

# Push everything
git remote add origin https://github.com/your-org/monorepo.git
git push -u origin main
```

---

## ðŸ“Š Expected Structure

```
monorepo/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ web-app/
â”‚   â””â”€â”€ mobile-ui/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api-users/
â”‚   â”œâ”€â”€ service-payments/
â”‚   â””â”€â”€ worker-notifications/
â”œâ”€â”€ libraries/
â”‚   â”œâ”€â”€ core-utils/
â”‚   â””â”€â”€ shared-components/
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ terraform-aws/
â”‚   â””â”€â”€ k8s-configs/
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ cli-tools/
â”‚   â””â”€â”€ scripts/
â””â”€â”€ README.md
```

---

## âš™ï¸ Configuration Options

### Batch Size
```bash
# Smaller batches = less memory, slower
# Larger batches = more memory, faster
BATCH_SIZE=25 ./merge-repos.sh repos-list.txt
```

### Parallel Jobs
```bash
# More jobs = faster (if you have CPU/network bandwidth)
PARALLEL_JOBS=20 ./merge-repos.sh repos-list.txt
```

### Skip Pushing
```bash
# Don't auto-push after each batch
unset REMOTE_URL
./merge-repos.sh repos-list.txt
```

---

## ðŸ› Troubleshooting

### "Fetch timeout or failed"
**Cause**: Repo is too large or network is slow

**Fix**:
```bash
# Increase timeout in merge-repos.sh
timeout 600 git fetch ...  # 10 minutes instead of 5
```

### "Could not add remote"
**Cause**: Repo doesn't exist or you lack permissions

**Fix**: Remove that line from `repos-list.txt`

### Out of Memory
**Cause**: Too many repos processed at once

**Fix**:
```bash
# Reduce batch size
BATCH_SIZE=10 ./merge-repos.sh repos-list.txt

# Or run git gc manually
cd monorepo && git gc --aggressive
```

### Rate Limiting
**Cause**: GitHub API limits

**Fix**:
- Use `GITHUB_TOKEN` for authentication
- Add delays: `sleep 1` between fetches
- Process during off-peak hours

---

## ðŸ”¥ Performance Optimization

### For 500 Repos:

**Estimated Time**:
- Sequential: ~8-12 hours
- Parallel (10 jobs): ~2-4 hours
- Parallel (20 jobs): ~1-2 hours

**Recommendations**:
```bash
# Fast machine with good internet
PARALLEL_JOBS=20 BATCH_SIZE=100 ./merge-repos.sh repos-list.txt

# Slower machine
PARALLEL_JOBS=5 BATCH_SIZE=25 ./merge-repos.sh repos-list.txt

# Conservative (safest)
PARALLEL_JOBS=1 BATCH_SIZE=10 ./merge-repos.sh repos-list.txt
```

---

## ðŸ“ Post-Merge Tasks

### 1. Update Documentation
```bash
cd monorepo

# Create root README
cat > README.md <<EOF
# Monorepo

This repository consolidates 500+ individual repositories.

## Structure
- \`frontend/\` - Web applications
- \`backend/\` - APIs and services
- \`libraries/\` - Shared code
- \`infrastructure/\` - DevOps configs

## Original Repositories
See [MIGRATION.md](MIGRATION.md) for mapping.
EOF

git add README.md
git commit -m "docs: add root README"
```

### 2. Create Migration Document
```bash
# Generate repo mapping
cat > MIGRATION.md <<EOF
# Repository Migration Map

| Original Repo | New Location |
|---------------|--------------|
EOF

awk -F: '{print "| " $1 " | `" $2 "` |"}' repos-list.txt >> MIGRATION.md

git add MIGRATION.md
git commit -m "docs: add migration mapping"
```

### 3. Archive Old Repositories

**Using GitHub CLI**:
```bash
# List all repos
gh repo list your-org --limit 1000 --json name,url > old-repos.json

# Archive them (careful!)
cat repos-list.txt | while IFS=: read -r url dir; do
    repo_name=$(basename "$url" .git)
    echo "Archiving $repo_name..."
    gh repo archive "your-org/$repo_name" --yes
done
```

**Manually**:
- Add deprecation notice to old repos
- Update README with link to monorepo
- Set as archived in GitHub settings

### 4. Update CI/CD
```bash
# Copy .github/workflows/ from old repos if needed
mkdir -p .github/workflows

# You'll need to consolidate workflows for the monorepo
# (This depends on your specific setup)
```

### 5. Fix Import Paths

If code references moved files:
```bash
# Example: Update import paths
find . -type f -name "*.js" -exec sed -i 's|@myorg/old-package|@myorg/monorepo/libraries/old-package|g' {} +

git add .
git commit -m "refactor: update import paths for monorepo"
```

---

## âš ï¸ Important Warnings

1. **Backup everything first** - Test on a small subset before running on all 500
2. **Check disk space** - 500 repos could be 10-100GB+
3. **Network bandwidth** - Fetching 500 repos = lots of data
4. **API rate limits** - Use authentication token
5. **Review conflicts** - Duplicate filenames across repos need manual resolution

---

## ðŸŽ¯ Advanced: Incremental Migration

Don't want to merge all 500 at once? Migrate in phases:

```bash
# Phase 1: Frontend only
grep "frontend/" repos-list.txt > phase1.txt
./merge-repos.sh phase1.txt

# Phase 2: Backend
grep "backend/" repos-list.txt > phase2.txt
./merge-repos.sh phase2.txt

# Phase 3: Everything else
grep -v "frontend/\|backend/" repos-list.txt > phase3.txt
./merge-repos.sh phase3.txt
```

---

## ðŸ“ž Need Help?

Common issues:
- **Script hangs**: Check `merge-logs/` for the last processed repo
- **Partial merge**: Just re-run the script - it skips existing directories
- **Want to start over**: `rm -rf monorepo/ merge-logs/` and run again

---

## âœ… Final Checklist

Before declaring victory:

- [ ] All 500 repos merged (check `summary.txt`)
- [ ] Structure makes sense (`tree -L 2 monorepo/`)
- [ ] Documentation updated (README, MIGRATION.md)
- [ ] Pushed to GitHub successfully
- [ ] CI/CD workflows configured
- [ ] Old repos archived with deprecation notices
- [ ] Team notified of new structure
- [ ] Import paths updated (if applicable)

---

## ðŸš€ You're Done!

You now have a single monorepo containing 500 repositories with:
- âœ… Full git history preserved
- âœ… Logical directory structure
- âœ… Complete audit trail in logs
- âœ… Ready for modern CI/CD

Welcome to monorepo life! ðŸŽ‰